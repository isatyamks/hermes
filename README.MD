Hierarchical Embodied Reinforcement Learning with LLM Supervision (HERMES)





#phase 1 : Pure RL Baseline (No Hierarchy, No LLM)


HERMES SYSTEM
â”‚
â”œâ”€â”€ base_ppo          â† this (low-level motor cortex)
â”‚
â”œâ”€â”€ skill_ppo         â† same control, skill rewards
â”‚
â”œâ”€â”€ curriculum_ppo    â† staged learning
â”‚
â””â”€â”€ hermes_ppo        â† RL + LLM supervision



ğŸ”§ Step 3.1 â€” Fix Height Measurement

Update hermes_logging/metrics.py:
def get_torso_height(obs):
    """
    MuJoCo Humanoid-v5 torso height.
    Observation layout:
    qpos starts at index 0
    z position is qpos[2]
    """
    return float(obs[2])


Then update episode_logger.py:

Replace this:
self.heights.append(obs[2])

With this:
from hermes_logging.metrics import get_torso_height
self.heights.append(get_torso_height(obs))


And in detect_fall() also use get_torso_height(obs).